"""
Utility functions for the Focus Group Generator
"""

import re
import io
import streamlit as st
from docx import Document
from docx.shared import Inches
import PyPDF2
import mammoth

def calculate_word_count(duration_minutes):
    """
    Calculate estimated word count based on scientific research
    
    Focus group discussions average ~133 words per minute with adjustments for:
    - Multiple speakers (reduces individual output)
    - Moderator participation (15% of total)
    - Natural pauses and thinking time
    """
    base_words_per_minute = 133
    group_size_factor = 0.85  # Multiple speakers reduce individual output
    moderator_factor = 0.15   # 15% moderator contribution
    
    total_words = int(duration_minutes * base_words_per_minute * group_size_factor)
    
    return total_words

def validate_api_key(provider, api_key):
    """
    Validate API key format for different providers
    """
    if not api_key:
        return False
    
    patterns = {
        'openai': r'^sk-[a-zA-Z0-9]{48,}$',
        'anthropic': r'^sk-ant-[a-zA-Z0-9\-_]{95,}$',
        'google': r'^[a-zA-Z0-9\-_]{39}$',
        'cohere': r'^[a-zA-Z0-9\-_]{40,}$',
        'mistral': r'^[a-zA-Z0-9]{32}$'
    }
    
    pattern = patterns.get(provider)
    if pattern:
        return bool(re.match(pattern, api_key))
    
    # Fallback: check if key is reasonable length
    return len(api_key) > 20

def export_to_txt(transcript, form_data):
    """
    Export transcript to plain text format
    """
    header = f"""FOCUS GROUP DISCUSSION TRANSCRIPT
Generated by Focus Group Generator
Date: {form_data.get('date', 'Not specified')}
Topic: {form_data.get('topic', 'Not specified')}
Duration: {form_data.get('duration', 0)} minutes
Location: {form_data.get('location', 'Not specified')}

{'='*50}

"""
    
    return header + transcript

def export_to_docx(transcript, form_data):
    """
    Export transcript to DOCX format with proper formatting
    """
    doc = Document()
    
    # Add title
    title = doc.add_heading('Focus Group Discussion Transcript', 0)
    title.alignment = 1  # Center alignment
    
    # Add metadata table
    doc.add_heading('Study Information', level=1)
    
    # Create a table for study details
    table = doc.add_table(rows=6, cols=2)
    table.style = 'Table Grid'
    
    # Populate table
    study_info = [
        ('Topic', form_data.get('topic', 'Not specified')),
        ('Duration', f"{form_data.get('duration', 0)} minutes"),
        ('Participants', f"{form_data.get('num_participants', 0)} people"),
        ('Location', form_data.get('location', 'Not specified')),
        ('Languages', ', '.join(form_data.get('languages', []))),
        ('Type', form_data.get('discussion_type', 'Not specified').title())
    ]
    
    for i, (key, value) in enumerate(study_info):
        table.cell(i, 0).text = key
        table.cell(i, 1).text = str(value)
    
    # Add transcript content
    doc.add_heading('Transcript', level=1)
    
    # Split transcript into paragraphs and format appropriately
    lines = transcript.split('\n')
    current_paragraph = ""
    
    for line in lines:
        line = line.strip()
        if not line:
            if current_paragraph:
                doc.add_paragraph(current_paragraph)
                current_paragraph = ""
        elif line.startswith('[') and ']' in line:
            # Timestamp and speaker lines
            if current_paragraph:
                doc.add_paragraph(current_paragraph)
                current_paragraph = ""
            p = doc.add_paragraph()
            p.add_run(line).bold = True
        elif line.startswith('---') or line.startswith('==='):
            # Separator lines
            doc.add_paragraph('_' * 50)
        else:
            current_paragraph += line + " "
    
    # Add any remaining content
    if current_paragraph:
        doc.add_paragraph(current_paragraph)
    
    # Save to bytes
    doc_io = io.BytesIO()
    doc.save(doc_io)
    doc_io.seek(0)
    
    return doc_io.getvalue()

def process_uploaded_file(uploaded_file):
    """
    Process uploaded file and extract text content
    """
    if uploaded_file is None:
        return ""
    
    file_extension = uploaded_file.name.split('.')[-1].lower()
    
    try:
        if file_extension == 'txt':
            # Plain text file
            content = uploaded_file.read().decode('utf-8')
            
        elif file_extension == 'pdf':
            # PDF file
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            content = ""
            for page in pdf_reader.pages:
                content += page.extract_text() + "\n"
                
        elif file_extension in ['docx', 'doc']:
            # Word document
            if file_extension == 'docx':
                result = mammoth.extract_raw_text(uploaded_file)
                content = result.value
            else:
                # For .doc files, we'll need python-docx2txt or similar
                st.warning("DOC files not fully supported. Please use DOCX format.")
                content = ""
                
        else:
            st.error(f"Unsupported file format: {file_extension}")
            content = ""
            
        return content.strip()
        
    except Exception as e:
        st.error(f"Error processing file: {str(e)}")
        return ""

def get_language_recommendations(selected_languages):
    """
    Get AI provider recommendations based on selected languages
    """
    recommendations = {
        'primary': None,
        'alternatives': [],
        'reasoning': ""
    }
    
    # Define language strengths for each provider
    provider_strengths = {
        'google': ['Hindi', 'Hinglish', 'Mandarin', 'Arabic'],
        'mistral': ['French'],
        'openai': ['English', 'Spanish'],
        'anthropic': ['English', 'Portuguese'],
        'cohere': ['English']
    }
    
    # Score providers based on language support
    scores = {}
    for provider, strong_langs in provider_strengths.items():
        score = len(set(selected_languages) & set(strong_langs))
        scores[provider] = score
    
    # Get recommendation
    best_provider = max(scores, key=scores.get)
    recommendations['primary'] = best_provider
    
    # Generate reasoning
    if 'Hindi' in selected_languages or 'Hinglish' in selected_languages:
        recommendations['reasoning'] = "Google AI recommended for superior Hindi/Hinglish support and Indian cultural context"
    elif len(selected_languages) == 1 and 'French' in selected_languages:
        recommendations['reasoning'] = "Mistral AI recommended for native French language excellence"
    elif len(selected_languages) == 1 and 'English' in selected_languages:
        recommendations['reasoning'] = "OpenAI recommended for best English conversation generation"
    else:
        recommendations['reasoning'] = "OpenAI recommended for best overall multi-language support"
    
    return recommendations

def format_transcript_preview(transcript, max_lines=20):
    """
    Format transcript for preview display
    """
    lines = transcript.split('\n')
    
    if len(lines) <= max_lines:
        return transcript
    
    preview_lines = lines[:max_lines]
    preview = '\n'.join(preview_lines)
    
    remaining_lines = len(lines) - max_lines
    preview += f"\n\n... ({remaining_lines} more lines)"
    
    return preview

def validate_form_data(form_data):
    """
    Validate form data completeness and consistency
    """
    errors = []
    warnings = []
    
    # Required fields
    required_fields = ['topic', 'objective', 'location']
    for field in required_fields:
        if not form_data.get(field):
            errors.append(f"Please fill in the {field.replace('_', ' ').title()} field")
    
    # Participant count validation
    total_participants = form_data.get('num_participants', 0)
    gender_sum = (form_data.get('male_count', 0) + 
                  form_data.get('female_count', 0) + 
                  form_data.get('non_binary_count', 0))
    
    if gender_sum != total_participants:
        errors.append(f"Gender counts ({gender_sum}) don't match total participants ({total_participants})")
    
    # Minimum participants
    if total_participants < 4:
        warnings.append("Focus groups typically work best with 6-12 participants")
    
    # Duration validation
    duration = form_data.get('duration', 0)
    if duration < 30:
        warnings.append("Very short duration may not provide sufficient discussion depth")
    elif duration > 120:
        warnings.append("Very long duration may lead to participant fatigue")
    
    # Language validation
    languages = form_data.get('languages', [])
    if not languages:
        errors.append("Please select at least one discussion language")
    
    return {
        'is_valid': len(errors) == 0,
        'errors': errors,
        'warnings': warnings
    }

def estimate_generation_time(duration, provider, model):
    """
    Estimate transcript generation time based on various factors
    """
    base_time = 30  # seconds
    
    # Duration factor (longer transcripts take more time)
    duration_factor = max(1.0, duration / 60)  # Scale based on 60-minute baseline
    
    # Provider speed factors (approximate)
    provider_speeds = {
        'google': 0.8,    # Fastest
        'cohere': 0.9,    # Fast
        'openai': 1.0,    # Baseline
        'mistral': 1.1,   # Slightly slower
        'anthropic': 1.2  # Most thorough, slightly slower
    }
    
    # Model speed factors
    model_speeds = {
        'gpt-3.5-turbo': 0.7,
        'gpt-4-turbo': 1.0,
        'gpt-4': 1.3,
        'claude-3-haiku': 0.8,
        'claude-3-sonnet': 1.0,
        'claude-3-opus': 1.4,
        'gemini-pro': 0.9,
        'command-light': 0.8,
        'command': 1.0,
        'mistral-small': 0.9,
        'mistral-medium': 1.0,
        'mistral-large': 1.2
    }
    
    provider_factor = provider_speeds.get(provider, 1.0)
    model_factor = model_speeds.get(model, 1.0)
    
    estimated_time = base_time * duration_factor * provider_factor * model_factor
    
    return int(estimated_time)

def generate_filename(topic, timestamp=None):
    """
    Generate a clean filename for exports
    """
    if timestamp is None:
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Clean topic for filename
    clean_topic = re.sub(r'[^\w\s-]', '', topic)
    clean_topic = re.sub(r'[-\s]+', '_', clean_topic)
    clean_topic = clean_topic.strip('_').lower()
    
    if len(clean_topic) > 30:
        clean_topic = clean_topic[:30]
    
    return f"focus_group_{clean_topic}_{timestamp}"